{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "27ae5533-bc8c-4dbc-b09a-b8c98053e687",
      "metadata": {
        "id": "27ae5533-bc8c-4dbc-b09a-b8c98053e687"
      },
      "source": [
        "#### Часть 1.\n",
        "\n",
        "Собственная имплементация"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "d99350a4-ed41-468c-b934-b1754883f3c1",
      "metadata": {
        "tags": [],
        "id": "d99350a4-ed41-468c-b934-b1754883f3c1"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1eb6583e-51f0-47c1-9d4c-be99d3f168f8",
      "metadata": {
        "id": "1eb6583e-51f0-47c1-9d4c-be99d3f168f8"
      },
      "source": [
        "Прочитаем текст:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a8a37f50-ea52-4685-8a10-564ca2e76a80",
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 104
        },
        "id": "a8a37f50-ea52-4685-8a10-564ca2e76a80",
        "outputId": "c0e8c297-cdfc-4aaf-ea2d-8d2413d45190"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Закон больших чисел (ЗБЧ) в теории вероятностей — принцип, описывающий результат выполнения одного и того же эксперимента много раз. Согласно закону, среднее значение конечной выборки из фиксированного распределения близко к математическому ожиданию этого распределения.\\n\\nДругими словами, чем больше объём выборки, тем чаще проводятся измерения какого-либо параметра, тем выше вероятность, что результаты окажутся близки к ожидаемым.\\n\\nЗакон больших чисел важен, поскольку он гарантирует устойчивость для средних значений некоторых случайных событий при достаточно длинной серии экспериментов.\\n\\nВажно помнить, что закон применим только тогда, когда рассматривается большое количество испытаний.\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "with open('zbch.txt') as f:\n",
        "    data = f.read()\n",
        "\n",
        "data"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "27e5c383-4b78-421c-8895-c923a0d4e429",
      "metadata": {
        "id": "27e5c383-4b78-421c-8895-c923a0d4e429"
      },
      "source": [
        "Разделим на слова:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "0fcc5d9f-b7d4-43c8-ae9f-b5742090d08f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0fcc5d9f-b7d4-43c8-ae9f-b5742090d08f",
        "outputId": "a3f5876e-091c-439e-dc1d-f66b59b8b7ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting razdel\n",
            "  Downloading razdel-0.5.0-py3-none-any.whl (21 kB)\n",
            "Installing collected packages: razdel\n",
            "Successfully installed razdel-0.5.0\n"
          ]
        }
      ],
      "source": [
        "!pip install razdel"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "63a1da92-90ee-4ac4-9475-31de086c13b8",
      "metadata": {
        "tags": [],
        "id": "63a1da92-90ee-4ac4-9475-31de086c13b8"
      },
      "outputs": [],
      "source": [
        "from razdel import tokenize\n",
        "\n",
        "ind_words = [t.text for t in tokenize(data)]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "7d3eafd6-4f06-4cbb-8eb2-e91a0bd660fe",
      "metadata": {
        "id": "7d3eafd6-4f06-4cbb-8eb2-e91a0bd660fe"
      },
      "source": [
        "Напишем функцию, которая будет нам собирать наши пары слов, и с ее помощью ниже получим словарь с переходами:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ba15a605-ecf1-40c4-81b8-844e177a30d8",
      "metadata": {
        "tags": [],
        "id": "ba15a605-ecf1-40c4-81b8-844e177a30d8"
      },
      "outputs": [],
      "source": [
        "def make_pairs(ind_words):\n",
        "    for i in range(len(ind_words) - 1):\n",
        "        yield ind_words[i], ind_words[i + 1]\n",
        "\n",
        "pair = make_pairs(ind_words)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "5db42b98-63c4-4edc-8ecc-511c43e957ff",
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5db42b98-63c4-4edc-8ecc-511c43e957ff",
        "outputId": "8d15b9f8-15f4-4948-8748-490a452766bb"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'Закон': ['больших', 'больших'],\n",
              " 'больших': ['чисел', 'чисел'],\n",
              " 'чисел': ['(', 'важен'],\n",
              " '(': ['ЗБЧ'],\n",
              " 'ЗБЧ': [')'],\n",
              " ')': ['в'],\n",
              " 'в': ['теории'],\n",
              " 'теории': ['вероятностей'],\n",
              " 'вероятностей': ['—'],\n",
              " '—': ['принцип'],\n",
              " 'принцип': [','],\n",
              " ',': ['описывающий',\n",
              "  'среднее',\n",
              "  'чем',\n",
              "  'тем',\n",
              "  'тем',\n",
              "  'что',\n",
              "  'поскольку',\n",
              "  'что',\n",
              "  'когда'],\n",
              " 'описывающий': ['результат'],\n",
              " 'результат': ['выполнения'],\n",
              " 'выполнения': ['одного'],\n",
              " 'одного': ['и'],\n",
              " 'и': ['того'],\n",
              " 'того': ['же'],\n",
              " 'же': ['эксперимента'],\n",
              " 'эксперимента': ['много'],\n",
              " 'много': ['раз'],\n",
              " 'раз': ['.'],\n",
              " '.': ['Согласно', 'Другими', 'Закон', 'Важно'],\n",
              " 'Согласно': ['закону'],\n",
              " 'закону': [','],\n",
              " 'среднее': ['значение'],\n",
              " 'значение': ['конечной'],\n",
              " 'конечной': ['выборки'],\n",
              " 'выборки': ['из', ','],\n",
              " 'из': ['фиксированного'],\n",
              " 'фиксированного': ['распределения'],\n",
              " 'распределения': ['близко', '.'],\n",
              " 'близко': ['к'],\n",
              " 'к': ['математическому', 'ожидаемым'],\n",
              " 'математическому': ['ожиданию'],\n",
              " 'ожиданию': ['этого'],\n",
              " 'этого': ['распределения'],\n",
              " 'Другими': ['словами'],\n",
              " 'словами': [','],\n",
              " 'чем': ['больше'],\n",
              " 'больше': ['объём'],\n",
              " 'объём': ['выборки'],\n",
              " 'тем': ['чаще', 'выше'],\n",
              " 'чаще': ['проводятся'],\n",
              " 'проводятся': ['измерения'],\n",
              " 'измерения': ['какого-либо'],\n",
              " 'какого-либо': ['параметра'],\n",
              " 'параметра': [','],\n",
              " 'выше': ['вероятность'],\n",
              " 'вероятность': [','],\n",
              " 'что': ['результаты', 'закон'],\n",
              " 'результаты': ['окажутся'],\n",
              " 'окажутся': ['близки'],\n",
              " 'близки': ['к'],\n",
              " 'ожидаемым': ['.'],\n",
              " 'важен': [','],\n",
              " 'поскольку': ['он'],\n",
              " 'он': ['гарантирует'],\n",
              " 'гарантирует': ['устойчивость'],\n",
              " 'устойчивость': ['для'],\n",
              " 'для': ['средних'],\n",
              " 'средних': ['значений'],\n",
              " 'значений': ['некоторых'],\n",
              " 'некоторых': ['случайных'],\n",
              " 'случайных': ['событий'],\n",
              " 'событий': ['при'],\n",
              " 'при': ['достаточно'],\n",
              " 'достаточно': ['длинной'],\n",
              " 'длинной': ['серии'],\n",
              " 'серии': ['экспериментов'],\n",
              " 'экспериментов': ['.'],\n",
              " 'Важно': ['помнить'],\n",
              " 'помнить': [','],\n",
              " 'закон': ['применим'],\n",
              " 'применим': ['только'],\n",
              " 'только': ['тогда'],\n",
              " 'тогда': [','],\n",
              " 'когда': ['рассматривается'],\n",
              " 'рассматривается': ['большое'],\n",
              " 'большое': ['количество'],\n",
              " 'количество': ['испытаний'],\n",
              " 'испытаний': ['.']}"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ],
      "source": [
        "word_dict = {}\n",
        "\n",
        "for word_1, word_2 in pair:\n",
        "    if word_1 in word_dict.keys():\n",
        "        word_dict[word_1].append(word_2)\n",
        "    else:\n",
        "        word_dict[word_1] = [word_2]\n",
        "\n",
        "word_dict"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6dac8615-a47a-40d9-b896-91dd712acfc0",
      "metadata": {
        "id": "6dac8615-a47a-40d9-b896-91dd712acfc0"
      },
      "source": [
        "Рандомно выберем первое слово и начнем генерировать текст длиной в 20 слов, случайно выбирая возможные следующие токены по предыдущему."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "66a8c7f0-a697-4b7b-b37c-0a95bbd3b502",
      "metadata": {
        "tags": [],
        "id": "66a8c7f0-a697-4b7b-b37c-0a95bbd3b502"
      },
      "outputs": [],
      "source": [
        "first_word = np.random.choice(ind_words)\n",
        "chain = [first_word]\n",
        "n_words = 20\n",
        "\n",
        "for i in range(n_words):\n",
        "    chain.append(np.random.choice(word_dict[chain[-1]]))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0511945e-fbe1-4c94-bfb4-08a48d7a56b3",
      "metadata": {
        "id": "0511945e-fbe1-4c94-bfb4-08a48d7a56b3"
      },
      "source": [
        "Наш обучающий текст был очень маленьким, поэтому, скорее всего, сгенерируются его же фрагменты вперемешку. На больших текстах результат будет интереснее."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1ebb5a45-4894-4568-adca-e9c3a5459050",
      "metadata": {
        "tags": [],
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ebb5a45-4894-4568-adca-e9c3a5459050",
        "outputId": "e134d457-1815-4558-e533-3bf6b35c266a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "измерения какого-либо параметра , когда рассматривается большое количество испытаний . Другими словами , описывающий результат выполнения одного и того же эксперимента\n"
          ]
        }
      ],
      "source": [
        "print(' '.join(chain))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e27af5c0-acb8-489f-93bc-9b323334805f",
      "metadata": {
        "id": "e27af5c0-acb8-489f-93bc-9b323334805f"
      },
      "source": [
        "#### Часть 2\n",
        "\n",
        "Теперь будем использовать готовую библиотеку markovify. Для предобработки текстов (возьмем Шекспира) нам понадобятся nltk и spacy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b664104d-155b-45e3-bb4c-a409ba50321e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b664104d-155b-45e3-bb4c-a409ba50321e",
        "outputId": "09454a45-c438-4d7b-b312-26cdf29522bd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting en-core-web-sm==3.7.1\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/en_core_web_sm-3.7.1/en_core_web_sm-3.7.1-py3-none-any.whl (12.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.8/12.8 MB\u001b[0m \u001b[31m53.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.2 in /usr/local/lib/python3.10/dist-packages (from en-core-web-sm==3.7.1) (3.7.4)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.2.3)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.1.2)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.3.4)\n",
            "Requirement already satisfied: typer<0.10.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.9.4)\n",
            "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (6.4.0)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.66.2)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.6.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.1.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (24.0)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.3.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (1.25.2)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.16.3 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.16.3)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (4.10.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (3.6)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2024.2.2)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.1.4)\n",
            "Requirement already satisfied: click<9.0.0,>=7.1.1 in /usr/local/lib/python3.10/dist-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (8.1.7)\n",
            "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (0.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.8.0,>=3.7.2->en-core-web-sm==3.7.1) (2.1.5)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('en_core_web_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ],
      "source": [
        "#!pip install nltk\n",
        "#!pip install spacy\n",
        "#!pip install markovify\n",
        "!python -m spacy download en_core_web_sm"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "12b42fd6-328a-4472-8885-3905d76ffa1e",
      "metadata": {
        "id": "12b42fd6-328a-4472-8885-3905d76ffa1e"
      },
      "source": [
        "Загрузим гутенберговский корпус из nltk и возьмем три пьесы Шекспира из него:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4969c8f4-b4fb-4e29-a49f-e213fcf60b04",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4969c8f4-b4fb-4e29-a49f-e213fcf60b04",
        "outputId": "8dc82c28-3b12-4c2f-aa31-4bdb7ae85c21"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['austen-emma.txt', 'austen-persuasion.txt', 'austen-sense.txt', 'bible-kjv.txt', 'blake-poems.txt', 'bryant-stories.txt', 'burgess-busterbrown.txt', 'carroll-alice.txt', 'chesterton-ball.txt', 'chesterton-brown.txt', 'chesterton-thursday.txt', 'edgeworth-parents.txt', 'melville-moby_dick.txt', 'milton-paradise.txt', 'shakespeare-caesar.txt', 'shakespeare-hamlet.txt', 'shakespeare-macbeth.txt', 'whitman-leaves.txt']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]   Package gutenberg is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import spacy\n",
        "import re\n",
        "import markovify\n",
        "from nltk.corpus import gutenberg\n",
        "import nltk\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "nltk.download('gutenberg')\n",
        "print(gutenberg.fileids())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2e15862d-2b07-42a0-87e5-b2421fe01f5a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2e15862d-2b07-42a0-87e5-b2421fe01f5a",
        "outputId": "e9bf8659-1c84-4832-e5cb-0d13cdeb0970"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Raw:\n",
            " [The Tragedie of Hamlet by William Shakespeare 1599]\n",
            "\n",
            "\n",
            "Actus Primus. Scoena Prima.\n",
            "\n",
            "Enter Barnardo a\n",
            "\n",
            "Raw:\n",
            " [The Tragedie of Macbeth by William Shakespeare 1603]\n",
            "\n",
            "\n",
            "Actus Primus. Scoena Prima.\n",
            "\n",
            "Thunder and Lig\n",
            "\n",
            "Raw:\n",
            " [The Tragedie of Julius Caesar by William Shakespeare 1599]\n",
            "\n",
            "\n",
            "Actus Primus. Scoena Prima.\n",
            "\n",
            "Enter Fla\n"
          ]
        }
      ],
      "source": [
        "hamlet = gutenberg.raw('shakespeare-hamlet.txt')\n",
        "macbeth = gutenberg.raw('shakespeare-macbeth.txt')\n",
        "caesar = gutenberg.raw('shakespeare-caesar.txt')\n",
        "# выведем по 100 первых символов\n",
        "print('\\nRaw:\\n', hamlet[:100])\n",
        "print('\\nRaw:\\n', macbeth[:100])\n",
        "print('\\nRaw:\\n', caesar[:100])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "4b96c77f-0410-495f-a30e-93523ae7b3b8",
      "metadata": {
        "id": "4b96c77f-0410-495f-a30e-93523ae7b3b8"
      },
      "source": [
        "Напишем всякие функции предобработки:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "17350789-b8cb-4abf-9cc2-12adc33134ce",
      "metadata": {
        "id": "17350789-b8cb-4abf-9cc2-12adc33134ce"
      },
      "outputs": [],
      "source": [
        "# поудаляем ненужные пробелы, отступы, пунктуацию и прочее\n",
        "def text_cleaner(text):\n",
        "    text = re.sub(r'--', ' ', text)\n",
        "    text = re.sub('[\\[].*?[\\]]', '', text)\n",
        "    text = re.sub(r'(\\b|\\s+\\-?|^\\-?)(\\d+|\\d*\\.\\d+)\\b','', text)\n",
        "    text = ' '.join(text.split())\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c12bf493-a088-469b-9278-74ccc3e64bb3",
      "metadata": {
        "id": "c12bf493-a088-469b-9278-74ccc3e64bb3"
      },
      "outputs": [],
      "source": [
        "# удалим заголовки глав\n",
        "hamlet = re.sub(r'Chapter \\d+', '', hamlet)\n",
        "macbeth = re.sub(r'Chapter \\d+', '', macbeth)\n",
        "caesar = re.sub(r'Chapter \\d+', '', caesar)\n",
        "# применим функции к текстам\n",
        "hamlet = text_cleaner(hamlet)\n",
        "caesar = text_cleaner(caesar)\n",
        "macbeth = text_cleaner(macbeth)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "444483e5-e93e-440b-bb47-33c0cc59553f",
      "metadata": {
        "id": "444483e5-e93e-440b-bb47-33c0cc59553f"
      },
      "outputs": [],
      "source": [
        "# распарсим с помощью спейси: это даст нам токены, предложения и потом части речи\n",
        "nlp = spacy.load('en_core_web_sm')\n",
        "hamlet_doc = nlp(hamlet)\n",
        "macbeth_doc = nlp(macbeth)\n",
        "caesar_doc = nlp(caesar)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "9f16b6ca-4f13-442e-9a39-2278caddb29b",
      "metadata": {
        "id": "9f16b6ca-4f13-442e-9a39-2278caddb29b"
      },
      "source": [
        "Соберем предложения, отсеяв однословные"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "870bf494-70fa-4e57-b176-85d62647ffd9",
      "metadata": {
        "id": "870bf494-70fa-4e57-b176-85d62647ffd9"
      },
      "outputs": [],
      "source": [
        "hamlet_sents = ' '.join([sent.text for sent in hamlet_doc.sents if len(sent.text) > 1])\n",
        "macbeth_sents = ' '.join([sent.text for sent in macbeth_doc.sents if len(sent.text) > 1])\n",
        "caesar_sents = ' '.join([sent.text for sent in caesar_doc.sents if len(sent.text) > 1])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "719ad057-2496-4773-af7f-7c19e0f6a6b4",
      "metadata": {
        "id": "719ad057-2496-4773-af7f-7c19e0f6a6b4"
      },
      "outputs": [],
      "source": [
        "shakespeare_sents = hamlet_sents + macbeth_sents + caesar_sents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "74a7eb48-c9ea-4e45-a18e-56d113d1b16e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "74a7eb48-c9ea-4e45-a18e-56d113d1b16e",
        "outputId": "d4b88645-5dd4-4d04-c493-b8ab98e4ec69"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Actus Primus. Scoena Prima. Enter Barnardo and Francisco two Centinels. Barnardo. Who's there? Fran. Nay answer me: Stand & vnfold your selfe Bar. Long liue the King Fran. Barnardo? Bar. He Fran. You come most carefully vpon your houre Bar. 'Tis now strook twelue, get thee to bed Francisco Fran. For\n"
          ]
        }
      ],
      "source": [
        "print(shakespeare_sents[:300])"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b6ae6246-b3be-484c-8aa5-01c75701eb29",
      "metadata": {
        "id": "b6ae6246-b3be-484c-8aa5-01c75701eb29"
      },
      "source": [
        "Теперь самое интересное: инициализируем наш markovify предложениями из текстов. Внутри этот объект уже сам сделает все, что нам надо, и нам останется только генерировать \"предложения\"."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e891c7ad-d860-4a53-ac67-a24e47afbd9f",
      "metadata": {
        "id": "e891c7ad-d860-4a53-ac67-a24e47afbd9f"
      },
      "outputs": [],
      "source": [
        "generator_1 = markovify.Text(shakespeare_sents, state_size=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2e24299f-39df-4b97-bbdf-e21db5571fb7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2e24299f-39df-4b97-bbdf-e21db5571fb7",
        "outputId": "26b5e1bd-5055-4473-9531-e48067e655c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n",
            "None\n",
            "None\n",
            "Why Friends, you go to bed Ham.\n",
            "My Lord, I haue Newes to tell you of it, I follow thee.\n",
            "I am so much a Foole, should I stay longer It would be spoke too Mar. Question it Horatio Hor.\n"
          ]
        }
      ],
      "source": [
        "# попробуем сгенерировать три предложения без всяких ограничений\n",
        "for i in range(3):\n",
        "    print(generator_1.make_sentence()) # генерировать текст\n",
        "\n",
        "# сгенерируем предложения с ограничением: не больше 100 символов\n",
        "for i in range(3):\n",
        "    print(generator_1.make_short_sentence(max_chars=100))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "86bb9207-f91d-458f-a395-fd807f9cfc08",
      "metadata": {
        "id": "86bb9207-f91d-458f-a395-fd807f9cfc08"
      },
      "source": [
        "Прикольно, но не совсем. Давайте для улучшения нашего генератора используем информацию о частях речи: мы ее просто приклеим к нашим токенам, переопределив пару методов в классе Text, так, чтобы при разбиении предложений в исходных данных он приклеивал части речи и использовал их, собирая матрицу переходов, а при создании генерированных предложений обратно отклеивал."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1228bdfa-2f47-4f71-b8f8-d9ae4e44cb0e",
      "metadata": {
        "id": "1228bdfa-2f47-4f71-b8f8-d9ae4e44cb0e"
      },
      "outputs": [],
      "source": [
        "class POSifiedText(markovify.Text):\n",
        "\n",
        "    def word_split(self, sentence):\n",
        "        return ['::'.join((word.orth_, word.pos_)) for word in nlp(sentence)]\n",
        "\n",
        "    def word_join(self, words):\n",
        "        sentence = ' '.join(word.split('::')[0] for word in words)\n",
        "        return sentence\n",
        "\n",
        "# инициализируем экземпляр доопределенного класса\n",
        "generator_2 = POSifiedText(shakespeare_sents, state_size=3)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1be34dab-b46a-4843-8b4b-3b09d4db98fd",
      "metadata": {
        "id": "1be34dab-b46a-4843-8b4b-3b09d4db98fd"
      },
      "source": [
        "А теперь потестим."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "4420c03f-b464-4f1a-bd62-ecdc82d00e7d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4420c03f-b464-4f1a-bd62-ecdc82d00e7d",
        "outputId": "84991c49-1940-4871-9644-4b3636fa30a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n",
            "Laertes , you but dally , I pray you giue me leaue .\n",
            "For vpon my life , I found no man , but he loues Brutus .\n",
            "He is about it , the Age is growne so great ?\n",
            "None\n",
            "When Lucius , when ? awake , I heere proclaime was madnesse  Was't Hamlet wrong'd Laertes ?\n",
            "No boasting like a Foole , should I stay longer It would be spoke too Mar. Question it Horatio Hor .\n",
            "They are comming to the Play  I must tell you then  You haue knowne what you should not Gent .\n",
            "I pray you all , Vpon this hope , that you may beleeue .\n",
            "You could for a need study a speech of fire , remain'd vnscorch'd .\n"
          ]
        }
      ],
      "source": [
        "for i in range(5):\n",
        "    print(generator_2.make_sentence())\n",
        "\n",
        "for i in range(5):\n",
        "    print(generator_2.make_short_sentence(max_chars=100))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f3cc73b2-cd8b-4839-b5f4-a1d2038b0a83",
      "metadata": {
        "id": "f3cc73b2-cd8b-4839-b5f4-a1d2038b0a83"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.14"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}